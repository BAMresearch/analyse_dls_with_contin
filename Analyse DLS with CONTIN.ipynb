{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This repository contains Python code and a Jupyter Notebook\n",
       "running the original [CONTIN program by S. Provencher](http://dx.doi.org/10.1016/0010-4655(82)90174-6)\n",
       "on every DLS measurement (dynamic light scattering, aka. photon correlation spectroscopy, PCS)\n",
       "read from `*.ASC` files at the specified angle found in the given subfolders.\n",
       "The expected input file format is `ALV-7004 CGS-8F Data` which is found at the first line of each file.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown as md\n",
    "from pathlib import Path\n",
    "md(Path(\"readme.md\").read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TODO\n",
    "- fix multicore (parallel) calc on Windows\n",
    "- [done] plot measured and fitted correlation curve\n",
    "- [done] reviewed units of *ptRange* and *fitRange* CONTIN parameters\n",
    "  - *fitRange* is given in meters now\n",
    "- [done] output peak statistics with uncertainties\n",
    "  - by calculating the statistics of lower and upper distribution (uncertainty subtracted from and added to distribution result) and using the max. absolute value\n",
    "- [done] float formatting in CONTIN input file fixed\n",
    "- [done] output CONTIN error message if no output was generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Parameters (please adjust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the measurement folder\n",
    "(And mind the scattering angle in a cell further down!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = '142 2020 MW002-02'\n",
    "dataDir = '../20210511/094 2021 PS-Standard 1zu1000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter_analysis_tools\n",
    "jupyter_analysis_tools.utils.setPackage(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from jupyter_analysis_tools.datalocations import getDataDirs, getDataFiles\n",
    "dataDirs = getDataDirs(dataDir, noWorkDir=True)\n",
    "#dataFiles = getDataFiles(dataDirs, include=\"*raged.ASC\")#, exclude=\"_average\")\n",
    "dataFiles = getDataFiles(dataDirs, include=\"*.ASC\", exclude=\"_average\")\n",
    "dataFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTIN parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continConfig = dict(recalc=True,\n",
    "    ptRangeSec=(3e-7, 1e0), fitRangeM=(1e-9, 300e-9), gridpts=200,\n",
    "    transformData=True, baselineCoeffs=0, # N_L\n",
    "    # weighs noise level of data points accordinly for photon correlation spectroscopy\n",
    "    # where the variance of Y is proportional to (Y**2+1)/(4*Y**2)\n",
    "    # (from contin.for, line 1430)\n",
    "    weighResiduals=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_analysis_tools.utils import updatedDict\n",
    "angles = [26, 34, 42, 50, 58, 66, 74, 82, 90, 98, 106, 114, 122, 130, 138, 146]\n",
    "continConfigs = [updatedDict(continConfig, 'angle', angle)\n",
    "                 for angle in (angles #74, 90, 130, 138\n",
    "                             )\n",
    "                ]\n",
    "#continConfigs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process given data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CONTIN on each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .contin import runContinOverFiles\n",
    "\n",
    "resultDirs = runContinOverFiles(dataFiles, continConfigs, nthreads=None)\n",
    "#resultDirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Runtime log (for reference):\n",
    "- for 3 measurements at 16 angles (=48): CONTIN analysis with 12 threads took 15.7,16.3,16.2 s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch CONTIN results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A single result curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .contin import getContinResults\n",
    "# show first result for testing\n",
    "dn = resultDirs[2]\n",
    "dfDistrib, dfFit, varmap = getContinResults(dn)\n",
    "dfDistrib.plot('radius', 'distrib', yerr='err', ecolor='salmon', grid=True, label=dn.name);\n",
    "print(varmap);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing a measure of uncertainties level along the curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_analysis_tools.distrib import normalizeDistrib, findPeakRanges, findLocalMinima\n",
    "ranges = findPeakRanges(dfDistrib.radius, dfDistrib.distrib, tol=1e-6)\n",
    "#findLocalMinima(ranges, dfDistrib.radius.values, dfDistrib.distrib.values, doPlot=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "for istart, iend in ranges:\n",
    "    x = dfDistrib.radius.values[istart:iend+1]\n",
    "    y = dfDistrib.distrib.values[istart:iend+1]\n",
    "    u = dfDistrib.err.values[istart:iend+1]\n",
    "    idx = np.where(y>0)\n",
    "    div = y[idx]/u[idx]\n",
    "    plt.errorbar(x, y, yerr=u, ecolor='salmon', label=r\"uncertainty lvl: $1/median(y/u)=$\"+f\"{1/np.median(div):.4g}\")\n",
    "    plt.grid(True);plt.legend()\n",
    "    #print(y[idx])\n",
    "    #print(u[idx])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test modified z-score for the count rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .dlshelpers import getDLSgammaSi, getDLSFileData\n",
    "from jupyter_analysis_tools.plotting import lineWidth\n",
    "angle = 26\n",
    "times = getDLSFileData(dataFiles[0])['countrate'].index.values\n",
    "countrates = np.stack([getDLSFileData(fn)['countrate'][angle].values for fn in dataFiles\n",
    "                       if angle in getDLSFileData(fn)['countrate']])\n",
    "median = np.median(countrates, axis=0)\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(times,countrates.T,\n",
    "         label=[f\"count rate {i} @{angle}\" for i in range(countrates.shape[0])])\n",
    "plt.plot(times, median, lw=lineWidth()*3, color=\"red\", label=\"median\")\n",
    "plt.xlabel(\"time (s)\"); plt.ylabel(\"Count Rate (kHz)\")\n",
    "plt.grid(); plt.legend();\n",
    "plt.xlim((20,30)); plt.ylim((median.min(), median.max()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_analysis_tools.analysis import getModZScore\n",
    "diff = np.sqrt(np.sum((countrates - median)**2, axis=-1))\n",
    "dict(diff=diff, med_abs_deviation=np.median(diff), scores=getModZScore(countrates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results from all files\n",
    "(The generalized object-oriented way, for an option of incorporating other methods than CONTIN too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from jupyter_analysis_tools.plotting import plotColor, initFigure, lineWidth\n",
    "from jupyter_analysis_tools.distrib import area, integrate, distrParLatex\n",
    "from jupyter_analysis_tools.distrib import normalizeDistrib, findPeakRanges, findLocalMinima, Distribution\n",
    "import numpy as np\n",
    "from .contin import getContinResults\n",
    "from .dlshelpers import getDLSFileData\n",
    "\n",
    "class ContinResult:\n",
    "    name = \"CONTIN\"\n",
    "    xColumn = \"radius\"; yColumn = \"distrib\"; uColumn = \"err\"\n",
    "    getResults = getContinResults\n",
    "    color = plotColor(1)\n",
    "\n",
    "class Results:\n",
    "    def __init__(self, filename, rtype=None):\n",
    "        self.rtype = rtype\n",
    "        self.sampleDir = Path(filename)\n",
    "        self.angle     = None\n",
    "        self.dfDistrib, self.dfFit, self.varmap = self.rtype.getResults(self.sampleDir, self.angle)\n",
    "        if self.dfDistrib is None: return\n",
    "        self.distrib = Distribution(self.dfDistrib[self.rtype.xColumn],\n",
    "                                    self.dfDistrib[self.rtype.yColumn],\n",
    "                                    self.dfDistrib[self.rtype.uColumn], maxPeakCount=1)\n",
    "\n",
    "    def plot(self, axes, subplotIdx=0):\n",
    "        if self.dfDistrib is None: return\n",
    "        self.plotCountRate(axes[subplotIdx])\n",
    "        self.plotCorrelationWithFit(axes[subplotIdx+1])\n",
    "        distPar, _ = self.distrib.peakDistrPar(plotAxes=axes, plotAxisStart=subplotIdx+3)\n",
    "        self.distrib.plot(axes[subplotIdx+2], distPar, name=self.rtype.name)\n",
    "\n",
    "    def plotCountRate(self, ax):\n",
    "        indata = getDLSFileData(self.varmap['dataFilename'])\n",
    "        angle = self.varmap['angle']\n",
    "        cr = indata['countrate']\n",
    "        cr.plot(y=angle, ax=ax, grid=True, lw=0.5,\n",
    "                label=( f\"@{angle:.0f}°\"\n",
    "                       +r\", $\\overline{CR}$=\"+f\"{cr[angle].mean():.1f} kHz\"\n",
    "                       +f\", score: {self.varmap['score']}\" if 'score' in self.varmap else \"\"),\n",
    "                xlabel=\"time (s)\", ylabel=\"Count Rate (kHz)\")\n",
    "\n",
    "    def plotCorrelationWithFit(self, ax):\n",
    "        \"\"\"plot fitted correlation curve with residual\"\"\"\n",
    "        ax.plot(self.dfFit['tau'], self.dfFit['corrIn'],\n",
    "               color=\"black\", lw=lineWidth()*2, label=\"measured\")\n",
    "        ax.plot(self.dfFit['tau'], self.dfFit['corrFit'],\n",
    "               color=self.rtype.color, label=\"fit\")\n",
    "        ax.legend()\n",
    "        ax2 = ax.twinx()\n",
    "        residual = self.dfFit['corrIn']-self.dfFit['corrFit']\n",
    "        ax2.plot(self.dfFit['tau'], residual, 'k.', alpha=.3, label=\"residual\")\n",
    "        ax2.set_ylim([-max(abs(residual)),max(abs(residual))])\n",
    "        # combine legends\n",
    "        ax2handles, ax2labels = ax2.get_legend_handles_labels()\n",
    "        axhandles, axlabels = ax.get_legend_handles_labels()\n",
    "        ax.legend(axhandles+ax2handles, axlabels+ax2labels)\n",
    "        ax.set_xlabel(r\"$\\tau$ (s)\"); ax.grid(); ax.set_xscale(\"log\");\n",
    "\n",
    "def plotResult(filename, withCountRate=False):\n",
    "    filename = Path(filename)\n",
    "    # CONTIN results\n",
    "    cnt = Results(filename, rtype=ContinResult)\n",
    "    if not cnt.distrib.peaks:\n",
    "        return # nothing to do\n",
    "    nsubplots = 2+len(cnt.distrib.peaks)+1\n",
    "    fig, axes = plt.subplots(1, nsubplots, dpi=100, gridspec_kw=dict(wspace=.4))\n",
    "    initFigure(fig, width=nsubplots*120, aspectRatio=nsubplots/1., quiet=True)\n",
    "    fig.suptitle(\"…\"+str(filename)[-60:], fontsize=10)\n",
    "    cnt.plot(axes)\n",
    "    plt.savefig(filename.with_suffix('.png'))\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [plotResult(resultDir, withCountRate=True) for resultDir in sorted(resultDirs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
